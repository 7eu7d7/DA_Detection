{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Called with args:\n",
      "Namespace(batch_size=1, checkepoch=1, checkpoint=0, checkpoint_interval=10000, checksession=1, class_agnostic=False, cuda=True, dataset='pascal_voc_0712', dataset_t='clipart', detach=True, disp_interval=100, ef=False, eta=0.1, gamma=5, gc=True, image_dir='images', large_scale=False, lc=False, load_name='models', lr=0.001, lr_decay_gamma=0.1, lr_decay_step=5, mGPUs=False, max_epochs=20, net='res101', num_workers=0, optimizer='sgd', resume=False, save_dir='./output', session=1, start_epoch=1, use_tfboard=False)\n",
      "Using config:\n",
      "{'ANCHOR_RATIOS': [0.5, 1, 2],\n",
      " 'ANCHOR_SCALES': [8, 16, 32],\n",
      " 'CROP_RESIZE_WITH_MAX_POOL': False,\n",
      " 'CUDA': False,\n",
      " 'DATA_DIR': '/mnt/g/py project/DA_Detection/data',\n",
      " 'DEDUP_BOXES': 0.0625,\n",
      " 'EPS': 1e-14,\n",
      " 'EXP_DIR': 'res101',\n",
      " 'FEAT_STRIDE': [16],\n",
      " 'GPU_ID': 0,\n",
      " 'MATLAB': 'matlab',\n",
      " 'MAX_NUM_GT_BOXES': 20,\n",
      " 'MOBILENET': {'DEPTH_MULTIPLIER': 1.0,\n",
      "               'FIXED_LAYERS': 5,\n",
      "               'REGU_DEPTH': False,\n",
      "               'WEIGHT_DECAY': 4e-05},\n",
      " 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),\n",
      " 'POOLING_MODE': 'align',\n",
      " 'POOLING_SIZE': 7,\n",
      " 'RESNET': {'FIXED_BLOCKS': 1, 'MAX_POOL': False},\n",
      " 'RESNET_PATH': 'weights/resnet101_caffe.pth',\n",
      " 'RNG_SEED': 3,\n",
      " 'ROOT_DIR': '/mnt/g/py project/DA_Detection',\n",
      " 'TEST': {'BBOX_REG': True,\n",
      "          'HAS_RPN': True,\n",
      "          'MAX_SIZE': 1000,\n",
      "          'MODE': 'nms',\n",
      "          'NMS': 0.3,\n",
      "          'PROPOSAL_METHOD': 'gt',\n",
      "          'RPN_MIN_SIZE': 16,\n",
      "          'RPN_NMS_THRESH': 0.7,\n",
      "          'RPN_POST_NMS_TOP_N': 300,\n",
      "          'RPN_PRE_NMS_TOP_N': 6000,\n",
      "          'RPN_TOP_N': 5000,\n",
      "          'SCALES': [600],\n",
      "          'SVM': False},\n",
      " 'TRAIN': {'ASPECT_GROUPING': False,\n",
      "           'BATCH_SIZE': 128,\n",
      "           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],\n",
      "           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],\n",
      "           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],\n",
      "           'BBOX_NORMALIZE_TARGETS': True,\n",
      "           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,\n",
      "           'BBOX_REG': True,\n",
      "           'BBOX_THRESH': 0.5,\n",
      "           'BG_THRESH_HI': 0.5,\n",
      "           'BG_THRESH_LO': 0.0,\n",
      "           'BIAS_DECAY': False,\n",
      "           'BN_TRAIN': False,\n",
      "           'DISPLAY': 20,\n",
      "           'DOUBLE_BIAS': False,\n",
      "           'FG_FRACTION': 0.25,\n",
      "           'FG_THRESH': 0.5,\n",
      "           'GAMMA': 0.1,\n",
      "           'HAS_RPN': True,\n",
      "           'IMS_PER_BATCH': 1,\n",
      "           'LEARNING_RATE': 0.001,\n",
      "           'MAX_SIZE': 1200,\n",
      "           'MOMENTUM': 0.9,\n",
      "           'PROPOSAL_METHOD': 'gt',\n",
      "           'RPN_BATCHSIZE': 256,\n",
      "           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],\n",
      "           'RPN_CLOBBER_POSITIVES': False,\n",
      "           'RPN_FG_FRACTION': 0.5,\n",
      "           'RPN_MIN_SIZE': 8,\n",
      "           'RPN_NEGATIVE_OVERLAP': 0.3,\n",
      "           'RPN_NMS_THRESH': 0.7,\n",
      "           'RPN_POSITIVE_OVERLAP': 0.7,\n",
      "           'RPN_POSITIVE_WEIGHT': -1.0,\n",
      "           'RPN_POST_NMS_TOP_N': 2000,\n",
      "           'RPN_POST_NMS_TOP_N_TARGET': 128,\n",
      "           'RPN_PRE_NMS_TOP_N': 12000,\n",
      "           'SCALES': [600],\n",
      "           'SNAPSHOT_ITERS': 5000,\n",
      "           'SNAPSHOT_KEPT': 3,\n",
      "           'SNAPSHOT_PREFIX': 'res101_faster_rcnn',\n",
      "           'STEPSIZE': [30000],\n",
      "           'SUMMARY_INTERVAL': 180,\n",
      "           'TRIM_HEIGHT': 600,\n",
      "           'TRIM_WIDTH': 600,\n",
      "           'TRUNCATED': False,\n",
      "           'USE_ALL_GT': True,\n",
      "           'USE_FLIPPED': True,\n",
      "           'USE_GT': False,\n",
      "           'WEIGHT_DECAY': 0.0001},\n",
      " 'USE_GPU_NMS': True,\n",
      " 'VGG_PATH': 'weights/vgg16_caffe.pth'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/g/py project/DA_Detection/lib/model/utils/config.py:377: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  yaml_cfg = edict(yaml.load(f))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing source data:\n",
      "Loaded dataset `voc_2007_trainval` for training\n",
      "Set proposal method: gt\n",
      "Appending horizontally-flipped training examples...\n",
      "voc_2007_trainval flipped images loaded from /mnt/g/py project/DA_Detection/data/cache/voc_2007_trainval_flipped_images.pkl\n",
      "voc_2007_trainval gt roidb loaded from /mnt/g/py project/DA_Detection/data/cache/voc_2007_trainval_gt_roidb.pkl\n",
      "done\n",
      "Preparing training data...\n",
      "voc_2007_trainval sizes loaded from /mnt/g/py project/DA_Detection/data/cache/voc_2007_trainval_img_sizes.pkl\n",
      "done\n",
      "Loaded dataset `voc_2012_trainval` for training\n",
      "Set proposal method: gt\n",
      "Appending horizontally-flipped training examples...\n",
      "voc_2012_trainval flipped images loaded from /mnt/g/py project/DA_Detection/data/cache/voc_2012_trainval_flipped_images.pkl\n",
      "voc_2012_trainval gt roidb loaded from /mnt/g/py project/DA_Detection/data/cache/voc_2012_trainval_gt_roidb.pkl\n",
      "done\n",
      "Preparing training data...\n",
      "voc_2012_trainval sizes loaded from /mnt/g/py project/DA_Detection/data/cache/voc_2012_trainval_img_sizes.pkl\n",
      "done\n",
      "before filtering, there are 33102 images...\n",
      "after filtering, there are 33102 images...\n",
      "Preparing target data:\n",
      "Loaded dataset `clipart_trainval` for training\n",
      "Set proposal method: gt\n",
      "Appending horizontally-flipped training examples...\n",
      "clipart_trainval flipped images loaded from /mnt/g/py project/DA_Detection/data/cache/clipart_trainval_flipped_images.pkl\n",
      "clipart_trainval gt roidb loaded from /mnt/g/py project/DA_Detection/data/cache/clipart_trainval_gt_roidb.pkl\n",
      "done\n",
      "Preparing training data...\n",
      "clipart_trainval sizes loaded from /mnt/g/py project/DA_Detection/data/cache/clipart_trainval_img_sizes.pkl\n",
      "done\n",
      "before filtering, there are 998 images...\n",
      "after filtering, there are 998 images...\n",
      "33102 source roidb entries\n",
      "998 target roidb entries\n",
      "Loading pretrained weights from weights/resnet101_caffe.pth\n",
      "[session 1][epoch  1][iter    0/10000] loss: 4.5008, lr: 1.00e-03\n",
      "\t\t\tfg/bg=(22/106), time cost: 0.736961\n",
      "\t\t\trpn_cls: 0.6802, rpn_box: 0.0557, rcnn_cls: 3.3161, rcnn_box 0.4488 dloss s: 0.0416 dloss t: 0.0023 dloss s pixel: 0.1250 dloss t pixel: 0.1250 eta: 0.1000\n",
      "[session 1][epoch  1][iter  100/10000] loss: 1.6437, lr: 1.00e-03\n",
      "\t\t\tfg/bg=(1/127), time cost: 30.830959\n",
      "\t\t\trpn_cls: 0.2130, rpn_box: 0.0019, rcnn_cls: 0.2222, rcnn_box 0.0005 dloss s: 0.0146 dloss t: 0.0048 dloss s pixel: 0.1252 dloss t pixel: 0.1247 eta: 0.1000\n",
      "[session 1][epoch  1][iter  200/10000] loss: 1.6616, lr: 1.00e-03\n",
      "\t\t\tfg/bg=(15/113), time cost: 30.315158\n",
      "\t\t\trpn_cls: 0.1179, rpn_box: 0.0099, rcnn_cls: 0.7566, rcnn_box 0.2776 dloss s: 0.0098 dloss t: 0.0203 dloss s pixel: 0.1252 dloss t pixel: 0.1246 eta: 0.1000\n"
     ]
    }
   ],
   "source": [
    "%run trainval_net_global_local.py --cuda --net res101 --dataset pascal_voc_0712 --dataset_t clipart --gc --save_dir ./output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "def fuck(a):\n",
    "    print(a())\n",
    "\n",
    "class A:\n",
    "    def __init__(self):\n",
    "        self.x=3\n",
    "    \n",
    "    def px(self):\n",
    "        fuck(lambda:self.x)\n",
    "\n",
    "\n",
    "aa=A()\n",
    "aa.x=5\n",
    "aa.px()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
